{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 12243536,
          "sourceType": "datasetVersion",
          "datasetId": 7714082
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Setup dan Instalasi Dependencies**\n",
        "- Instalasi `ultralytics` (YOLOv8) dan `supervision` untuk computer vision\n",
        "- Import library yang diperlukan: OpenCV, pandas, matplotlib, seaborn, dll\n",
        "- Setup warnings dan konfigurasi dasar"
      ],
      "metadata": {
        "id": "d5YoF8DVG4EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "! pip install ultralytics -qq\n",
        "! pip install supervision -qq\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:40:43.88302Z",
          "iopub.execute_input": "2025-06-22T06:40:43.883698Z",
          "iopub.status.idle": "2025-06-22T06:42:04.118796Z",
          "shell.execute_reply.started": "2025-06-22T06:40:43.883675Z",
          "shell.execute_reply": "2025-06-22T06:42:04.118008Z"
        },
        "id": "LIgkku9G_nLt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "import subprocess\n",
        "from IPython.display import Video\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "print(cv2.__version__)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:42:04.120471Z",
          "iopub.execute_input": "2025-06-22T06:42:04.120758Z",
          "iopub.status.idle": "2025-06-22T06:42:08.368453Z",
          "shell.execute_reply.started": "2025-06-22T06:42:04.120733Z",
          "shell.execute_reply": "2025-06-22T06:42:08.36724Z"
        },
        "id": "Y_4vwGjZ_nLu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Konfigurasi Model dan Parameter**\n",
        "- Model weights (YOLOv8s.pt)\n",
        "- Parameter deteksi: confidence threshold (0.35), IOU threshold (0.5)\n",
        "- Parameter heatmap: alpha, radius, kernel size\n",
        "- Parameter tracking: durasi, threshold matching\n",
        "- Path file video input dan output"
      ],
      "metadata": {
        "id": "pVBkGuKsHEZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    ### YOLOv8/YOLOv9 custom or pretrained model\n",
        "    MODEL_WEIGHTS = 'yolov8s.pt' # yolov8s.pt, yolov9c.pt, yolov9e.pt\n",
        "\n",
        "    ### detections (YOLO)\n",
        "    CONFIDENCE = 0.35\n",
        "    IOU = 0.5\n",
        "\n",
        "    ### heatmap (Supervision)\n",
        "    HEATMAP_ALPHA = 0.30\n",
        "    RADIUS = 20\n",
        "\n",
        "    ### tracking (Supervision)\n",
        "    TRACK_SECONDS = 5\n",
        "    TRACK_THRESH = 0.35\n",
        "    MATCH_THRESH = 0.9999\n",
        "\n",
        "    ### paths: video file path, webcam is 0\n",
        "    VIDEO_FILE = \"/kaggle/input/datathon-data/part2(split-video.com).mp4\"\n",
        "    OUTPUT_PATH = './'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:42:08.376881Z",
          "iopub.execute_input": "2025-06-22T06:42:08.377176Z",
          "iopub.status.idle": "2025-06-22T06:42:08.395255Z",
          "shell.execute_reply.started": "2025-06-22T06:42:08.377152Z",
          "shell.execute_reply": "2025-06-22T06:42:08.394395Z"
        },
        "id": "TYmq-1L3_nLu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Utilitas Video Processing**\n",
        "- Fungsi `get_video_properties()` untuk mendapatkan informasi video (FPS, dimensi, durasi, dll)\n",
        "- Ekstraksi dan tampilan properti video input\n",
        "- Konversi codec video menggunakan FFmpeg untuk kompatibilitas"
      ],
      "metadata": {
        "id": "E321vomlHQTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_properties(video_path):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Check if the video file is opened successfully\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(\"Could not open video file\")\n",
        "\n",
        "    # Get video properties\n",
        "    properties = {\n",
        "        \"fps\": int(cap.get(cv2.CAP_PROP_FPS)),\n",
        "        \"frame_count\": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "        \"duration_seconds\": int( cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS) ),\n",
        "        \"width\": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        \"height\": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "        \"codec\": int(cap.get(cv2.CAP_PROP_FOURCC)),\n",
        "    }\n",
        "\n",
        "    # Release the video capture object\n",
        "    cap.release()\n",
        "\n",
        "    return properties"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:42:08.396016Z",
          "iopub.execute_input": "2025-06-22T06:42:08.396304Z",
          "iopub.status.idle": "2025-06-22T06:42:08.418994Z",
          "shell.execute_reply.started": "2025-06-22T06:42:08.396281Z",
          "shell.execute_reply": "2025-06-22T06:42:08.417693Z"
        },
        "id": "wbKSkxwZ_nLv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "video_properties = get_video_properties(CFG.VIDEO_FILE)\n",
        "video_properties"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:42:08.420496Z",
          "iopub.execute_input": "2025-06-22T06:42:08.420868Z",
          "iopub.status.idle": "2025-06-22T06:42:08.563578Z",
          "shell.execute_reply.started": "2025-06-22T06:42:08.420845Z",
          "shell.execute_reply": "2025-06-22T06:42:08.562779Z"
        },
        "id": "5MsrTCLU_nLv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_VIDEO_NAME = f'{CFG.OUTPUT_PATH}original_new_codec.mp4'\n",
        "\n",
        "subprocess.run(\n",
        "    [\n",
        "        \"ffmpeg\",  \"-i\", CFG.VIDEO_FILE, \"-crf\",\n",
        "        \"18\", \"-preset\", \"veryfast\", \"-hide_banner\", \"-loglevel\",\n",
        "        \"error\", \"-vcodec\", \"libx264\", OUT_VIDEO_NAME\n",
        "    ]\n",
        ")\n",
        "\n",
        "Video(\n",
        "    data = OUT_VIDEO_NAME,\n",
        "    embed = True,\n",
        "    height = int(video_properties['height'] * 0.5),\n",
        "    width = int(video_properties['width'] * 0.5)\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:42:08.564298Z",
          "iopub.execute_input": "2025-06-22T06:42:08.564526Z",
          "iopub.status.idle": "2025-06-22T06:42:16.515174Z",
          "shell.execute_reply.started": "2025-06-22T06:42:08.564506Z",
          "shell.execute_reply": "2025-06-22T06:42:16.514447Z"
        },
        "id": "Plg_2L_R_nLv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. **Inisialisasi Model dan Annotator**\n",
        "- Load model YOLOv8 pretrained\n",
        "- Setup heatmap annotator dengan parameter visual\n",
        "- Setup label annotator untuk menampilkan ID tracker\n",
        "- Konfigurasi ByteTrack untuk object tracking\n",
        "- Setup video processing pipeline\n"
      ],
      "metadata": {
        "id": "F-SFVysDHYji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"/kaggle/working/yolov8s.pt\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:42:16.516047Z",
          "iopub.execute_input": "2025-06-22T06:42:16.516293Z",
          "iopub.status.idle": "2025-06-22T06:42:20.408907Z",
          "shell.execute_reply.started": "2025-06-22T06:42:16.516275Z",
          "shell.execute_reply": "2025-06-22T06:42:20.408158Z"
        },
        "id": "A9Lc2Wfq_nLw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "### heatmap config\n",
        "heat_map_annotator = sv.HeatMapAnnotator(\n",
        "    position = sv.Position.BOTTOM_CENTER,\n",
        "    opacity = CFG.HEATMAP_ALPHA,\n",
        "    radius = CFG.RADIUS,\n",
        "    kernel_size = 25,\n",
        "    top_hue = 0,\n",
        "    low_hue = 125,\n",
        ")\n",
        "\n",
        "### annotation config\n",
        "label_annotator = sv.LabelAnnotator(text_position = sv.Position.CENTER)\n",
        "\n",
        "### tracker config\n",
        "byte_tracker = sv.ByteTrack(\n",
        "    track_activation_threshold=CFG.TRACK_THRESH,\n",
        "    lost_track_buffer=CFG.TRACK_SECONDS * video_properties[\"fps\"],\n",
        "    minimum_matching_threshold=CFG.MATCH_THRESH,\n",
        "    frame_rate=video_properties[\"fps\"],\n",
        ")\n",
        "\n",
        "### video config\n",
        "video_info = sv.VideoInfo.from_video_path(video_path = CFG.VIDEO_FILE)\n",
        "frames_generator = sv.get_video_frames_generator(source_path = CFG.VIDEO_FILE, stride = 1)\n",
        "output_filename = f'{CFG.OUTPUT_PATH}heatmap_output_c{int(CFG.CONFIDENCE * 100)}_iou{int(CFG.IOU * 100)}.mp4'\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:42:20.415839Z",
          "iopub.execute_input": "2025-06-22T06:42:20.416032Z",
          "iopub.status.idle": "2025-06-22T06:43:03.202656Z",
          "shell.execute_reply.started": "2025-06-22T06:42:20.416018Z",
          "shell.execute_reply": "2025-06-22T06:43:03.202049Z"
        },
        "id": "e-FNoEe-_nLw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. **Proses Deteksi dan Tracking Utama**\n",
        "- Loop untuk setiap frame video\n",
        "- Deteksi objek manusia (class 0) menggunakan YOLO\n",
        "- Update tracker untuk konsistensi ID antar frame\n",
        "- Penyimpanan tracking data (koordinat, confidence, ID, dll)\n",
        "- Annotasi frame dengan heatmap dan label ID\n",
        "- Export hasil ke video baru\n",
        "\n",
        "**Output**:\n",
        "- Video dengan overlay heatmap dan tracking ID\n",
        "- Data tracking dalam format CSV"
      ],
      "metadata": {
        "id": "GN2M_-0xHgz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tambahkan list untuk menyimpan tracking data\n",
        "tracking_data = []\n",
        "\n",
        "### Detect, track, annotate, save\n",
        "with sv.VideoSink(target_path = output_filename, video_info = video_info) as sink:\n",
        "\n",
        "    frame_idx = 0\n",
        "    for frame in frames_generator:\n",
        "        result = model(\n",
        "            source = frame,\n",
        "            classes = [0], # only person class\n",
        "            conf = CFG.CONFIDENCE,\n",
        "            iou = CFG.IOU,\n",
        "            half = True,\n",
        "            show_conf = True,\n",
        "            save_txt = True,\n",
        "            save_conf = True,\n",
        "            save = True,\n",
        "            device = 0, # dual GPU\n",
        "            batch=16,\n",
        "        )[0]\n",
        "\n",
        "        detections = sv.Detections.from_ultralytics(result) # get detections\n",
        "\n",
        "        detections = byte_tracker.update_with_detections(detections) # update tracker\n",
        "\n",
        "        # Simpan tracking data\n",
        "        for i, (bbox, tracker_id, confidence, class_id) in enumerate(zip(\n",
        "            detections.xyxy,\n",
        "            detections.tracker_id,\n",
        "            detections.confidence,\n",
        "            detections.class_id\n",
        "        )):\n",
        "            x1, y1, x2, y2 = bbox\n",
        "            x_center = (x1 + x2) / 2 / frame.shape[1]  # normalize\n",
        "            y_center = (y1 + y2) / 2 / frame.shape[0]  # normalize\n",
        "            width = (x2 - x1) / frame.shape[1]  # normalize\n",
        "            height = (y2 - y1) / frame.shape[0]  # normalize\n",
        "\n",
        "            tracking_data.append({\n",
        "                'frame': frame_idx,\n",
        "                'tracker_id': tracker_id,\n",
        "                'class': class_id,\n",
        "                'class_name': model.names[class_id],\n",
        "                'x_center': x_center,\n",
        "                'y_center': y_center,\n",
        "                'width': width,\n",
        "                'height': height,\n",
        "                'confidence': confidence\n",
        "            })\n",
        "\n",
        "        ### draw heatmap\n",
        "        annotated_frame = heat_map_annotator.annotate(\n",
        "            scene = frame.copy(),\n",
        "            detections = detections\n",
        "        )\n",
        "\n",
        "        ### draw other attributes from `detections` object\n",
        "        labels = [\n",
        "            f\"#{tracker_id}\"\n",
        "            for class_id, tracker_id\n",
        "            in zip(detections.class_id, detections.tracker_id)\n",
        "        ]\n",
        "\n",
        "        label_annotator.annotate(\n",
        "            scene = annotated_frame,\n",
        "            detections = detections,\n",
        "            labels = labels\n",
        "        )\n",
        "\n",
        "        sink.write_frame(frame = annotated_frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "clear_output()\n"
      ],
      "metadata": {
        "id": "ddFsMCEcFuAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan tracking data ke CSV\n",
        "tracking_df = pd.DataFrame(tracking_data)\n",
        "tracking_df.to_csv(f'{CFG.OUTPUT_PATH}tracking_results.csv', index=False)"
      ],
      "metadata": {
        "id": "gB3LjVC4FxMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. **Konversi dan Tampilan Hasil**\n",
        "- Konversi video hasil dengan codec yang kompatibel\n",
        "- Tampilan video hasil dalam notebook\n",
        "- Parsing dan tampilan data prediksi dari file YOLO format"
      ],
      "metadata": {
        "id": "T8mMxogXHmkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IN_VIDEO_NAME = f'{CFG.OUTPUT_PATH}heatmap_output_c{int(CFG.CONFIDENCE * 100)}_iou{int(CFG.IOU * 100)}.mp4' # detected video on output or predict folder\n",
        "OUT_VIDEO_NAME = f'{CFG.OUTPUT_PATH}heatmap_and_track.mp4' # detected video new codec\n",
        "\n",
        "subprocess.run(\n",
        "    [\n",
        "        \"ffmpeg\",  \"-i\", IN_VIDEO_NAME, \"-crf\",\n",
        "        \"18\", \"-preset\", \"veryfast\", \"-hide_banner\", \"-loglevel\",\n",
        "        \"error\", \"-vcodec\", \"libx264\", OUT_VIDEO_NAME\n",
        "    ]\n",
        ")\n",
        "\n",
        "Video(\n",
        "    data = OUT_VIDEO_NAME,\n",
        "    embed = True,\n",
        "    height = int(video_properties['height'] * 0.5),\n",
        "    width = int(video_properties['width'] * 0.5)\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:44:24.334397Z",
          "iopub.execute_input": "2025-06-22T06:44:24.335121Z",
          "iopub.status.idle": "2025-06-22T06:44:24.980892Z",
          "shell.execute_reply.started": "2025-06-22T06:44:24.335096Z",
          "shell.execute_reply": "2025-06-22T06:44:24.980095Z"
        },
        "id": "j2Shbeo-_nLw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = f'{CFG.OUTPUT_PATH}runs/detect/predict/labels/image0.txt'\n",
        "\n",
        "columns = ['class', 'x_center', 'y_center', 'width', 'height', 'confidence']\n",
        "predictions = pd.read_csv(file_path, delimiter=' ', header=None, names=columns)\n",
        "\n",
        "### add column class_name\n",
        "predictions['class_name'] = predictions['class'].map(model.names)\n",
        "predictions = predictions[['class_name'] + columns] # reorder\n",
        "predictions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T06:44:37.698622Z",
          "iopub.execute_input": "2025-06-22T06:44:37.699144Z",
          "iopub.status.idle": "2025-06-22T06:44:37.718231Z",
          "shell.execute_reply.started": "2025-06-22T06:44:37.699122Z",
          "shell.execute_reply": "2025-06-22T06:44:37.717633Z"
        },
        "id": "YDmsbW2S_nLw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. **Fungsi Analisis Data Tracking**\n",
        "- `generate_person_logs_and_heatmap()`: Konversi tracking data ke format analisis\n",
        "- `generate_person_log()`: Membuat log detail untuk setiap person\n",
        "- `generate_heatmap_data()`: Membuat data heatmap berdasarkan grid\n",
        "- `generate_summary_stats()`: Statistik ringkasan keseluruhan\n",
        "- Konversi koordinat normalized ke pixel coordinates"
      ],
      "metadata": {
        "id": "EkGIUTOgHpxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_person_logs_and_heatmap(tracking_data, video_properties, output_path='./'):\n",
        "    \"\"\"\n",
        "    Generate person detection logs and heatmap data from existing tracking results.\n",
        "\n",
        "    Args:\n",
        "        tracking_data (list): Your existing tracking_data list\n",
        "        video_properties (dict): Your existing video_properties dict\n",
        "        output_path (str): Path to save output files (default: './')\n",
        "\n",
        "    Returns:\n",
        "        tuple: (person_log_df, heatmap_data_df, summary_stats)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🔄 Processing tracking data for person logs and heatmap...\")\n",
        "\n",
        "    # Convert tracking data to DataFrame\n",
        "    df = pd.DataFrame(tracking_data)\n",
        "\n",
        "    # Calculate time stamps\n",
        "    fps = video_properties['fps']\n",
        "    df['timestamp_seconds'] = df['frame'] / fps\n",
        "    df['timestamp_formatted'] = df['timestamp_seconds'].apply(\n",
        "        lambda x: str(timedelta(seconds=int(x)))\n",
        "    )\n",
        "\n",
        "    # Convert normalized coordinates back to pixel coordinates\n",
        "    frame_width = video_properties['width']\n",
        "    frame_height = video_properties['height']\n",
        "\n",
        "    df['x_pixel'] = df['x_center'] * frame_width\n",
        "    df['y_pixel'] = df['y_center'] * frame_height\n",
        "    df['bbox_left'] = (df['x_center'] - df['width']/2) * frame_width\n",
        "    df['bbox_top'] = (df['y_center'] - df['height']/2) * frame_height\n",
        "    df['bbox_right'] = (df['x_center'] + df['width']/2) * frame_width\n",
        "    df['bbox_bottom'] = (df['y_center'] + df['height']/2) * frame_height\n",
        "\n",
        "    print(f\"📊 Found {df['tracker_id'].nunique()} unique persons in {len(df)} total detections\")\n",
        "\n",
        "    return df, fps, frame_width, frame_height"
      ],
      "metadata": {
        "id": "oqI7qehED2B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_person_log(df, fps, frame_width, frame_height):\n",
        "    \"\"\"Generate detailed person detection logs\"\"\"\n",
        "\n",
        "    person_log = []\n",
        "\n",
        "    for person_id in df['tracker_id'].unique():\n",
        "        person_data = df[df['tracker_id'] == person_id].sort_values('frame')\n",
        "\n",
        "        # Calculate person statistics\n",
        "        first_detection = person_data.iloc[0]\n",
        "        last_detection = person_data.iloc[-1]\n",
        "        total_detections = len(person_data)\n",
        "        avg_confidence = person_data['confidence'].mean()\n",
        "\n",
        "        # Calculate movement statistics\n",
        "        positions = person_data[['x_pixel', 'y_pixel']].values\n",
        "        if len(positions) > 1:\n",
        "            distances = np.sqrt(np.sum(np.diff(positions, axis=0)**2, axis=1))\n",
        "            total_distance = np.sum(distances)\n",
        "            max_distance = np.max(distances) if len(distances) > 0 else 0\n",
        "        else:\n",
        "            total_distance = 0\n",
        "            max_distance = 0\n",
        "\n",
        "        # Calculate time spent in different areas (divide frame into quadrants)\n",
        "        mid_x, mid_y = frame_width / 2, frame_height / 2\n",
        "        quadrant_time = {\n",
        "            'top_left': 0, 'top_right': 0, 'bottom_left': 0, 'bottom_right': 0\n",
        "        }\n",
        "\n",
        "        for _, row in person_data.iterrows():\n",
        "            x, y = row['x_pixel'], row['y_pixel']\n",
        "            if x < mid_x and y < mid_y:\n",
        "                quadrant_time['top_left'] += 1\n",
        "            elif x >= mid_x and y < mid_y:\n",
        "                quadrant_time['top_right'] += 1\n",
        "            elif x < mid_x and y >= mid_y:\n",
        "                quadrant_time['bottom_left'] += 1\n",
        "            else:\n",
        "                quadrant_time['bottom_right'] += 1\n",
        "\n",
        "        # Convert frame counts to time\n",
        "        for quadrant in quadrant_time:\n",
        "            quadrant_time[quadrant] = quadrant_time[quadrant] / fps\n",
        "\n",
        "        person_log.append({\n",
        "            'person_id': int(person_id),\n",
        "            'first_detected_frame': int(first_detection['frame']),\n",
        "            'first_detected_time': first_detection['timestamp_formatted'],\n",
        "            'first_detected_seconds': round(first_detection['timestamp_seconds'], 2),\n",
        "            'last_detected_frame': int(last_detection['frame']),\n",
        "            'last_detected_time': last_detection['timestamp_formatted'],\n",
        "            'last_detected_seconds': round(last_detection['timestamp_seconds'], 2),\n",
        "            'total_detection_frames': total_detections,\n",
        "            'detection_duration_seconds': round(last_detection['timestamp_seconds'] - first_detection['timestamp_seconds'], 2),\n",
        "            'average_confidence': round(avg_confidence, 3),\n",
        "            'total_movement_distance_pixels': round(total_distance, 2),\n",
        "            'max_frame_movement_pixels': round(max_distance, 2),\n",
        "            'time_in_top_left_seconds': round(quadrant_time['top_left'], 2),\n",
        "            'time_in_top_right_seconds': round(quadrant_time['top_right'], 2),\n",
        "            'time_in_bottom_left_seconds': round(quadrant_time['bottom_left'], 2),\n",
        "            'time_in_bottom_right_seconds': round(quadrant_time['bottom_right'], 2),\n",
        "            'avg_x_position': round(person_data['x_pixel'].mean(), 2),\n",
        "            'avg_y_position': round(person_data['y_pixel'].mean(), 2),\n",
        "            'x_position_std': round(person_data['x_pixel'].std(), 2),\n",
        "            'y_position_std': round(person_data['y_pixel'].std(), 2)\n",
        "        })\n",
        "\n",
        "    person_log_df = pd.DataFrame(person_log)\n",
        "    print(f\"👥 Generated detailed logs for {len(person_log_df)} persons\")\n",
        "\n",
        "    return person_log_df"
      ],
      "metadata": {
        "id": "UKvLwSP4EXVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_heatmap_data(df, frame_width, frame_height, fps):\n",
        "    \"\"\"Generate heatmap data from tracking results\"\"\"\n",
        "\n",
        "    print(\"🔥 Generating heatmap data...\")\n",
        "    heatmap_data = []\n",
        "\n",
        "    # Create a grid for heatmap (divide frame into cells)\n",
        "    grid_size = 20  # 20x20 grid\n",
        "    x_bins = np.linspace(0, frame_width, grid_size + 1)\n",
        "    y_bins = np.linspace(0, frame_height, grid_size + 1)\n",
        "\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            x_min, x_max = x_bins[i], x_bins[i + 1]\n",
        "            y_min, y_max = y_bins[j], y_bins[j + 1]\n",
        "\n",
        "            # Count detections in this grid cell\n",
        "            in_cell = df[\n",
        "                (df['x_pixel'] >= x_min) & (df['x_pixel'] < x_max) &\n",
        "                (df['y_pixel'] >= y_min) & (df['y_pixel'] < y_max)\n",
        "            ]\n",
        "\n",
        "            detection_count = len(in_cell)\n",
        "            unique_persons = in_cell['tracker_id'].nunique() if detection_count > 0 else 0\n",
        "            avg_confidence = in_cell['confidence'].mean() if detection_count > 0 else 0\n",
        "\n",
        "            heatmap_data.append({\n",
        "                'grid_x': i,\n",
        "                'grid_y': j,\n",
        "                'x_min': round(x_min, 1),\n",
        "                'x_max': round(x_max, 1),\n",
        "                'y_min': round(y_min, 1),\n",
        "                'y_max': round(y_max, 1),\n",
        "                'x_center': round((x_min + x_max) / 2, 1),\n",
        "                'y_center': round((y_min + y_max) / 2, 1),\n",
        "                'detection_count': detection_count,\n",
        "                'unique_persons': unique_persons,\n",
        "                'avg_confidence': round(avg_confidence, 3) if detection_count > 0 else 0,\n",
        "                'time_spent_seconds': round(detection_count / fps, 2)\n",
        "            })\n",
        "\n",
        "    heatmap_data_df = pd.DataFrame(heatmap_data)\n",
        "\n",
        "    return heatmap_data_df"
      ],
      "metadata": {
        "id": "AAoaDZbeEbDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary_stats(df, person_log_df, heatmap_data_df):\n",
        "    \"\"\"Generate summary statistics\"\"\"\n",
        "\n",
        "    summary_stats = {\n",
        "        'total_unique_persons': int(df['tracker_id'].nunique()),\n",
        "        'total_detections': len(df),\n",
        "        'video_duration_seconds': round(df['timestamp_seconds'].max(), 2),\n",
        "        'average_persons_per_frame': round(df.groupby('frame')['tracker_id'].nunique().mean(), 2),\n",
        "        'max_persons_in_single_frame': int(df.groupby('frame')['tracker_id'].nunique().max()),\n",
        "        'most_active_person_id': int(person_log_df.loc[person_log_df['total_detection_frames'].idxmax(), 'person_id']),\n",
        "        'longest_tracked_person_id': int(person_log_df.loc[person_log_df['detection_duration_seconds'].idxmax(), 'person_id']),\n",
        "        'most_active_grid_cell': {\n",
        "            'x': int(heatmap_data_df.loc[heatmap_data_df['detection_count'].idxmax(), 'grid_x']),\n",
        "            'y': int(heatmap_data_df.loc[heatmap_data_df['detection_count'].idxmax(), 'grid_y']),\n",
        "            'detections': int(heatmap_data_df['detection_count'].max())\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return summary_stats"
      ],
      "metadata": {
        "id": "OI41I29OEgXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. **Fungsi Visualisasi**\n",
        "- `plot_person_timeline()`: Timeline kehadiran setiap person\n",
        "- `plot_detection_heatmap()`: Heatmap intensitas deteksi di area frame\n",
        "- `plot_activity_analysis()`: Analisis aktivitas (durasi, movement, confidence)\n",
        "- `display_summary_stats()`: Format tampilan statistik\n",
        "- `save_results()`: Penyimpanan hasil ke file CSV dan JSON"
      ],
      "metadata": {
        "id": "MoP0ogriH9YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_person_timeline(person_log_df, output_path, timestamp):\n",
        "    \"\"\"Generate person timeline visualization\"\"\"\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 8))\n",
        "\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(person_log_df)))\n",
        "\n",
        "    for i, (_, person) in enumerate(person_log_df.iterrows()):\n",
        "        person_id = person['person_id']\n",
        "        start_time = person['first_detected_seconds']\n",
        "        end_time = person['last_detected_seconds']\n",
        "\n",
        "        ax.barh(person_id, end_time - start_time, left=start_time, height=0.6,\n",
        "                alpha=0.8, color=colors[i], edgecolor='black', linewidth=0.5)\n",
        "\n",
        "    ax.set_xlabel('Time (seconds)', fontsize=12)\n",
        "    ax.set_ylabel('Person ID', fontsize=12)\n",
        "    ax.set_title('Person Detection Timeline', fontsize=14, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_path}person_timeline_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "W8y1ciRxEj4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_detection_heatmap(heatmap_data_df, output_path, timestamp):\n",
        "    \"\"\"Generate detection heatmap visualization\"\"\"\n",
        "\n",
        "    grid_size = int(np.sqrt(len(heatmap_data_df)))\n",
        "    heatmap_matrix = heatmap_data_df['detection_count'].values.reshape(grid_size, grid_size)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 10))\n",
        "    im = ax.imshow(heatmap_matrix, cmap='YlOrRd', aspect='auto')\n",
        "    ax.set_title('Person Detection Heatmap\\n(Warmer colors = More detections)', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('X Grid Position (Left → Right)', fontsize=12)\n",
        "    ax.set_ylabel('Y Grid Position (Top → Bottom)', fontsize=12)\n",
        "\n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(im, ax=ax)\n",
        "    cbar.set_label('Detection Count', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_path}detection_heatmap_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "i4ZqYf-HEmKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_activity_analysis(person_log_df, output_path, timestamp):\n",
        "    \"\"\"Generate person activity analysis plots\"\"\"\n",
        "\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # Detection duration distribution\n",
        "    ax1.hist(person_log_df['detection_duration_seconds'], bins=min(15, len(person_log_df)),\n",
        "             alpha=0.7, edgecolor='black', color='skyblue')\n",
        "    ax1.set_xlabel('Detection Duration (seconds)')\n",
        "    ax1.set_ylabel('Number of Persons')\n",
        "    ax1.set_title('Distribution of Person Detection Durations')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Movement distance distribution\n",
        "    ax2.hist(person_log_df['total_movement_distance_pixels'], bins=min(15, len(person_log_df)),\n",
        "             alpha=0.7, edgecolor='black', color='lightcoral')\n",
        "    ax2.set_xlabel('Total Movement Distance (pixels)')\n",
        "    ax2.set_ylabel('Number of Persons')\n",
        "    ax2.set_title('Distribution of Person Movement Distances')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # Confidence distribution\n",
        "    ax3.hist(person_log_df['average_confidence'], bins=min(15, len(person_log_df)),\n",
        "             alpha=0.7, edgecolor='black', color='lightgreen')\n",
        "    ax3.set_xlabel('Average Confidence Score')\n",
        "    ax3.set_ylabel('Number of Persons')\n",
        "    ax3.set_title('Distribution of Average Confidence Scores')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # Detection count per person\n",
        "    ax4.bar(person_log_df['person_id'], person_log_df['total_detection_frames'],\n",
        "            alpha=0.7, edgecolor='black', color='orange')\n",
        "    ax4.set_xlabel('Person ID')\n",
        "    ax4.set_ylabel('Total Detection Frames')\n",
        "    ax4.set_title('Detection Count per Person')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_path}person_activity_analysis_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "jj6kgxulEpWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_summary_stats(summary_stats):\n",
        "    \"\"\"Display summary statistics in a nice format\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"📊 DETECTION SUMMARY STATISTICS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"👥 Total unique persons detected: {summary_stats['total_unique_persons']}\")\n",
        "    print(f\"🎯 Total detections: {summary_stats['total_detections']:,}\")\n",
        "    print(f\"⏱  Video duration: {summary_stats['video_duration_seconds']:.1f} seconds\")\n",
        "    print(f\"📈 Average persons per frame: {summary_stats['average_persons_per_frame']:.2f}\")\n",
        "    print(f\"🏆 Maximum persons in single frame: {summary_stats['max_persons_in_single_frame']}\")\n",
        "    print(f\"🔥 Most active person: ID #{summary_stats['most_active_person_id']}\")\n",
        "    print(f\"⏰ Longest tracked person: ID #{summary_stats['longest_tracked_person_id']}\")\n",
        "    print(f\"📍 Hottest spot: Grid ({summary_stats['most_active_grid_cell']['x']}, {summary_stats['most_active_grid_cell']['y']}) with {summary_stats['most_active_grid_cell']['detections']} detections\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "def save_results(person_log_df, heatmap_data_df, summary_stats, output_path):\n",
        "    \"\"\"Save all results to files\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Save person log\n",
        "    person_log_filename = f'{output_path}person_detection_log_{timestamp}.csv'\n",
        "    person_log_df.to_csv(person_log_filename, index=False)\n",
        "\n",
        "    # Save heatmap data\n",
        "    heatmap_filename = f'{output_path}heatmap_data_{timestamp}.csv'\n",
        "    heatmap_data_df.to_csv(heatmap_filename, index=False)\n",
        "\n",
        "    # Save summary stats\n",
        "    summary_filename = f'{output_path}detection_summary_{timestamp}.json'\n",
        "    with open(summary_filename, 'w') as f:\n",
        "        json.dump(summary_stats, f, indent=2)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"✅ ANALYSIS COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"📋 Person detection log: {person_log_filename}\")\n",
        "    print(f\"🔥 Heatmap data: {heatmap_filename}\")\n",
        "    print(f\"📊 Summary statistics: {summary_filename}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return timestamp"
      ],
      "metadata": {
        "id": "kUqds1GbEtMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. **Eksekusi Analisis Lengkap**\n",
        "- Eksekusi pipeline lengkap dari tracking data ke insights\n",
        "- Generate person logs dengan detail movement dan timing\n",
        "- Generate heatmap data dengan grid 20x20\n",
        "- Kalkulasi summary statistics\n",
        "- Export semua hasil ke file dengan timestamp"
      ],
      "metadata": {
        "id": "ZdkUJRwvIGaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the complete analysis\n",
        "print(\"🚀 Starting person detection and heatmap analysis...\")\n",
        "\n",
        "# Step 1: Process basic data\n",
        "df, fps, frame_width, frame_height = generate_person_logs_and_heatmap(\n",
        "    tracking_data, video_properties, CFG.OUTPUT_PATH\n",
        ")\n",
        "\n",
        "# Step 2: Generate person logs\n",
        "person_log_df = generate_person_log(df, fps, frame_width, frame_height)\n",
        "\n",
        "# Step 3: Generate heatmap data\n",
        "heatmap_data_df = generate_heatmap_data(df, frame_width, frame_height, fps)\n",
        "\n",
        "# Step 4: Generate summary statistics\n",
        "summary_stats = generate_summary_stats(df, person_log_df, heatmap_data_df)\n",
        "\n",
        "# Step 5: Save results\n",
        "timestamp = save_results(person_log_df, heatmap_data_df, summary_stats, CFG.OUTPUT_PATH)\n",
        "\n",
        "# Step 6: Display summary\n",
        "display_summary_stats(summary_stats)"
      ],
      "metadata": {
        "id": "PZE2d_7_ExJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. **Visualisasi dan Display Hasil**\n",
        "- Generate dan tampilkan semua visualisasi:\n",
        "  - Timeline chart person detection\n",
        "  - Heatmap deteksi area\n",
        "  - Histogram analisis aktivitas (durasi, movement, confidence)\n",
        "- Display sample data dan top hotspots"
      ],
      "metadata": {
        "id": "IG5laYW7IRrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate all visualizations\n",
        "print(\"📈 Generating visualizations...\")\n",
        "\n",
        "# Timeline plot\n",
        "plot_person_timeline(person_log_df, CFG.OUTPUT_PATH, timestamp)\n",
        "\n",
        "# Heatmap plot\n",
        "plot_detection_heatmap(heatmap_data_df, CFG.OUTPUT_PATH, timestamp)\n",
        "\n",
        "# Activity analysis plots\n",
        "plot_activity_analysis(person_log_df, CFG.OUTPUT_PATH, timestamp)\n",
        "\n",
        "print(\"✅ All visualizations generated!\")"
      ],
      "metadata": {
        "id": "yCJQDoJKE0CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first few rows of person log\n",
        "print(\"\\n👥 SAMPLE PERSON DETECTION LOG:\")\n",
        "print(person_log_df.head())\n",
        "\n",
        "# Display top hotspots from heatmap\n",
        "print(\"\\n🔥 TOP 5 HOTSPOTS:\")\n",
        "top_hotspots = heatmap_data_df.nlargest(5, 'detection_count')[\n",
        "    ['grid_x', 'grid_y', 'detection_count', 'unique_persons', 'time_spent_seconds']\n",
        "]\n",
        "print(top_hotspots)"
      ],
      "metadata": {
        "id": "NSUshE8uE5RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. **Analisis Detail Individual (Optional)**\n",
        "- `analyze_specific_person()`: Analisis mendalam untuk person tertentu\n",
        "- Plot trajectory movement individual\n",
        "- Statistik detail movement dan behavior pattern\n",
        "- Visualization path pergerakan dengan color coding berdasarkan frame"
      ],
      "metadata": {
        "id": "_iI4eG5dINyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Analyze specific person in detail\n",
        "def analyze_specific_person(person_id, df, person_log_df):\n",
        "    \"\"\"Analyze a specific person in detail\"\"\"\n",
        "\n",
        "    # Get person data\n",
        "    person_data = df[df['tracker_id'] == person_id].sort_values('frame')\n",
        "    person_info = person_log_df[person_log_df['person_id'] == person_id].iloc[0]\n",
        "\n",
        "    print(f\"\\n🔍 DETAILED ANALYSIS FOR PERSON ID: {person_id}\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Detection duration: {person_info['detection_duration_seconds']:.2f} seconds\")\n",
        "    print(f\"Total movement: {person_info['total_movement_distance_pixels']:.2f} pixels\")\n",
        "    print(f\"Average confidence: {person_info['average_confidence']:.3f}\")\n",
        "    print(f\"Average position: ({person_info['avg_x_position']:.1f}, {person_info['avg_y_position']:.1f})\")\n",
        "\n",
        "    # Plot person trajectory\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(person_data['x_pixel'], person_data['y_pixel'], 'b-', alpha=0.7, linewidth=2)\n",
        "    plt.scatter(person_data['x_pixel'], person_data['y_pixel'],\n",
        "                c=person_data['frame'], cmap='viridis', s=30, alpha=0.8)\n",
        "    plt.colorbar(label='Frame Number')\n",
        "    plt.xlabel('X Position (pixels)')\n",
        "    plt.ylabel('Y Position (pixels)')\n",
        "    plt.title(f'Movement Trajectory - Person ID {person_id}')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.gca().invert_yaxis()  # Invert Y axis to match image coordinates\n",
        "    plt.show()\n",
        "\n",
        "# Example usage (uncomment to use):\n",
        "# analyze_specific_person(1, df, person_log_df)  # Analyze person with ID 1"
      ],
      "metadata": {
        "id": "Xcv4oQDeFJXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ringkasan Workflow:**\n",
        "\n",
        "1. **Input**: Video file → **Output**: Annotated video + tracking data\n",
        "2. **Processing**: YOLO detection + ByteTrack tracking + heatmap generation  \n",
        "3. **Analysis**: Person logs + movement analytics + area hotspots\n",
        "4. **Visualization**: Timeline charts + heatmaps + activity distributions\n",
        "5. **Export**: CSV files + JSON summaries + PNG visualizations"
      ],
      "metadata": {
        "id": "7KCEcnj9IVAO"
      }
    }
  ]
}