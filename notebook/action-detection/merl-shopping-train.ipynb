{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q \"transformers[torch]\" accelerate datasets evaluate decord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependensi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset menggunakan dari MERL yang udah kuupload di huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-30T14:05:42.756566Z",
     "iopub.status.busy": "2025-06-30T14:05:42.756026Z",
     "iopub.status.idle": "2025-06-30T14:05:54.569439Z",
     "shell.execute_reply": "2025-06-30T14:05:54.568894Z",
     "shell.execute_reply.started": "2025-06-30T14:05:42.756542Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from HuggingFace...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8591eb8eb21841bba3bf4dcdae3894c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 214 files:   0%|          | 0/214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc0ea55a98541b9b28fd335a5c11ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "28_3_label.mat:   0%|          | 0.00/420 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db5092044d2402698c91f177268b8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "27_2_label.mat:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8152435061654910acdb51086ecc0873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "28_2_label.mat:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a2cf5fbe0448d098bb1c67642099fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "27_3_label.mat:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04912567024f49c9be611fb21839372f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "28_1_label.mat:   0%|          | 0.00/406 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa9bae2a58f4574bca9a6982e2b71bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "30_2_label.mat:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f873cf9e54426f9932eaf9470b22cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "30_1_label.mat:   0%|          | 0.00/478 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557c3c39029e400a85db71147565388e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "29_2_label.mat:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297e7c56eda94fff9f19c5c7b1fb1bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "29_3_label.mat:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d69506fdd7482ca1189c3b1c531bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "29_1_label.mat:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df19c3e148f34fefb9da76a680760e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "31_2_label.mat:   0%|          | 0.00/563 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5198c50a884525b716149d3b4a798a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "30_3_label.mat:   0%|          | 0.00/430 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37c083adde645ffacfdb5da54b0d9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "31_1_label.mat:   0%|          | 0.00/440 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceacc5e369284f04af553218ffcc6f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "31_3_label.mat:   0%|          | 0.00/406 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806a00694a16440d9360a36f0071dfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "32_2_label.mat:   0%|          | 0.00/496 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2bd8f88f084ed4ac2163914fca4d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "32_1_label.mat:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6ba56759f743d6876314bbe13718a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "32_3_label.mat:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28493f9e72da41fbb7ef952b90e828a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "34_1_label.mat:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d1363b192747ae820780d0e2db4f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "35_1_label.mat:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3930d81179e4c758f93b6443bf83f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "33_1_label.mat:   0%|          | 0.00/458 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bafe483818d4b85b6eb71c4317b0225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "9_1_label.mat:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38411190fb6d430d99d30ca3846ab4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "21_2_label.mat:   0%|          | 0.00/451 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5fb19ddf9f47dea4488612c4e95ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "21_1_label.mat:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ddbe9c90347278973b4282cb45655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "23_1_label.mat:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2774440b7ab43e39e4acd8e8cc9c9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "22_3_label.mat:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee979a80f23412f81cc83d75272c9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "22_1_label.mat:   0%|          | 0.00/368 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6691609a2743caafe26ec38b403dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "22_2_label.mat:   0%|          | 0.00/374 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f264a870c9cd4424acf493dfa8b501aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "23_2_label.mat:   0%|          | 0.00/464 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddc8a13bd244b16b771996a7000f2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "21_3_label.mat:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f0e3a369144ff798f21b89f107c765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_1_crop.mp4:   0%|          | 0.00/15.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b4ce962ff24822a9b44c75694b64ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_2_crop.mp4:   0%|          | 0.00/15.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e357eb4b37ab4ddfaabe7249f135f29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_3_crop.mp4:   0%|          | 0.00/22.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d003648cca004b079de60d492f4f876d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20_1_crop.mp4:   0%|          | 0.00/16.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b769e907f2504702bd5fe7cb32b7921b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20_2_crop.mp4:   0%|          | 0.00/21.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c0f0323bf444c4865fcd003eff50f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_1_crop.mp4:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386e052403bb4146b47b60f5b3453ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_2_crop.mp4:   0%|          | 0.00/16.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f237930d69c45bd9991acfac4b9e4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20_3_crop.mp4:   0%|          | 0.00/20.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5868be151e4d5986c0c9ffaf5f923c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_3_crop.mp4:   0%|          | 0.00/16.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2545efe5f5ec4cd8b43cc953d43383d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_1_crop.mp4:   0%|          | 0.00/13.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8dbe4c13ea422bba37a38c684ea719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_2_crop.mp4:   0%|          | 0.00/19.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd26f87626f47a0aeb7f1a5c0c0d7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_3_crop.mp4:   0%|          | 0.00/15.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7746906590ca441baa5a89ce50032864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4_1_crop.mp4:   0%|          | 0.00/15.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd58a8f2b4514b4b8a2f8cff441d2ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4_3_crop.mp4:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a1cbc0f2204a27a89d3074c9a85ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4_2_crop.mp4:   0%|          | 0.00/15.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5dedc2e3c24847b0db997a9af5a18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5_1_crop.mp4:   0%|          | 0.00/15.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ac3876cc0d4a76a7b47250e4ba05d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5_2_crop.mp4:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866b2579a06c4bcd96d0e04a2fb9d821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5_3_crop.mp4:   0%|          | 0.00/18.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0798cdfffe6047218f77d579bcaf2adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6_1_crop.mp4:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942798b6f0cb402390db8922b017e264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6_3_crop.mp4:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8c2f6017d0493f9fa3f9af4df494ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6_2_crop.mp4:   0%|          | 0.00/16.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297d0aba95344e9c951c70fe4c4afaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "7_1_crop.mp4:   0%|          | 0.00/14.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b618072d3f56474da5501cf12f267728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "7_2_crop.mp4:   0%|          | 0.00/16.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03130392c0484ba399f4ac7bdcbeba3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "7_3_crop.mp4:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3f65b408d94c82b661d3a7f02b07ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "8_2_crop.mp4:   0%|          | 0.00/19.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f37528b8a84ff792b7f34154fbd409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "8_1_crop.mp4:   0%|          | 0.00/14.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e143642a8c4583920afcc3a1ccca55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "8_3_crop.mp4:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86014dad75064c70b00930df2f92210a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "9_1_crop.mp4:   0%|          | 0.00/15.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1068a6450deb429583769aca79ab5acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "9_2_crop.mp4:   0%|          | 0.00/16.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1103e64f8f1740e79c3276c730f8eca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "9_3_crop.mp4:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b8d3d56e7741e1b3823ec02f682e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "21_1_crop.mp4:   0%|          | 0.00/15.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b98d0e06d0a44819c46fcd6edf0b9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "21_3_crop.mp4:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89959611769b4dcaa3320db6c3662fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "22_1_crop.mp4:   0%|          | 0.00/18.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019f63c5783a453c8775823cc4e39807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "21_2_crop.mp4:   0%|          | 0.00/17.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7d9ef09ce344748227eb1e5879989a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "22_2_crop.mp4:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46727521f3764758b85fc416aaa64a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "22_3_crop.mp4:   0%|          | 0.00/18.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912eba8fe3034749a0b32ecef541d065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "23_1_crop.mp4:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d6711dfec4496e9d0bf27098fde219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "23_2_crop.mp4:   0%|          | 0.00/21.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8253b377ec854c0b8521e90cdb169858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "23_3_crop.mp4:   0%|          | 0.00/26.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae65d897031640e28a44a39760ba2fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "24_1_crop.mp4:   0%|          | 0.00/17.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0601c98b04a48698aa406726d5a2e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "24_2_crop.mp4:   0%|          | 0.00/19.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd03d19b1c1404197d604bd88f4f501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "24_3_crop.mp4:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e8810f6a7c4be8ba3573e62a902f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "25_1_crop.mp4:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a9975b544c41f3862b714a8e17af4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "25_2_crop.mp4:   0%|          | 0.00/19.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4f27971895425980580351f4c29e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "25_3_crop.mp4:   0%|          | 0.00/17.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffe4b4ffab442aea45476e042e02702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "26_1_crop.mp4:   0%|          | 0.00/17.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df6ba032b3941fa8d1f3a622abd8891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "26_2_crop.mp4:   0%|          | 0.00/18.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc52dcca78c44e5ab732884e2d41a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "26_3_crop.mp4:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "WORK_DIR = \"/kaggle/working\"\n",
    "DATASET_DIR = os.path.join(WORK_DIR, \"MERL_Shopping_Dataset\")\n",
    "VIDEOS_DIR = os.path.join(DATASET_DIR, \"videos\")\n",
    "LABELS_DIR = os.path.join(DATASET_DIR, \"labels\")\n",
    "\n",
    "# --- Download Dataset ---\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "    print(\"Downloading dataset from HuggingFace...\")\n",
    "    snapshot_download(\n",
    "        repo_id=\"haipradana/merl-shopping-action-detection\",\n",
    "        repo_type=\"dataset\",\n",
    "        local_dir=DATASET_DIR\n",
    "    )\n",
    "    print(\"Dataset downloaded!\")\n",
    "else:\n",
    "    print(\"Dataset already exists in working directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasete dimerge antara train/test/split supaya memudahkan dalam memuat klip video dari frame dengan decord dengan fungsi create_clips_dataframe. Nanti displit lagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-30T14:06:20.712417Z",
     "iopub.status.busy": "2025-06-30T14:06:20.712068Z",
     "iopub.status.idle": "2025-06-30T14:06:22.511637Z",
     "shell.execute_reply": "2025-06-30T14:06:22.511027Z",
     "shell.execute_reply.started": "2025-06-30T14:06:20.712392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-split folders found. Merging them into single directories...\n",
      "Merging complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Gabungkan Folder Train/Val/Test (jika ada) ---\n",
    "if os.path.exists(os.path.join(VIDEOS_DIR, \"train\")):\n",
    "    print(\"Pre-split folders found. Merging them into single directories...\")\n",
    "    # Buat direktori sementara untuk penggabungan\n",
    "    merged_videos_dir = f\"{DATASET_DIR}/videos_merged\"\n",
    "    merged_labels_dir = f\"{DATASET_DIR}/labels_merged\"\n",
    "    os.makedirs(merged_videos_dir, exist_ok=True)\n",
    "    os.makedirs(merged_labels_dir, exist_ok=True)\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        # Gabungkan video\n",
    "        split_videos_path = os.path.join(VIDEOS_DIR, split)\n",
    "        if os.path.exists(split_videos_path):\n",
    "            for f in os.listdir(split_videos_path):\n",
    "                shutil.copy(os.path.join(split_videos_path, f), merged_videos_dir)\n",
    "        # Gabungkan label\n",
    "        split_labels_path = os.path.join(LABELS_DIR, split)\n",
    "        if os.path.exists(split_labels_path):\n",
    "            for f in os.listdir(split_labels_path):\n",
    "                shutil.copy(os.path.join(split_labels_path, f), merged_labels_dir)\n",
    "\n",
    "    # Ganti folder lama dengan yang sudah digabung\n",
    "    shutil.rmtree(VIDEOS_DIR)\n",
    "    shutil.rmtree(LABELS_DIR)\n",
    "    shutil.move(merged_videos_dir, VIDEOS_DIR)\n",
    "    shutil.move(merged_labels_dir, LABELS_DIR)\n",
    "    print(\"Merging complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing label dan Membuat Clips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load datset label .mat dengan scipy.io loadmat. Ini membaca file label untuk mengetahui di frame berapa saja sebuah aksi terjadi (misalnya, \"Reach To Shelf\" terjadi dari frame 100 hingga 150).\n",
    "2. Membuat fungsi create_clips_dataframe(videos_dir, labels_dir), untuk memetakan video dan labelnya. Lalu membuat sebuah daftar (yang kemudian menjadi Pandas DataFrame) yang berisi instruksi. Setiap baris dalam DataFrame itu adalah satu \"klip virtual\" yang didefinisikan oleh:\n",
    "- video_id: Video mana yang harus digunakan.\n",
    "- start_frame: Mulai dari frame ke berapa.\n",
    "- end_frame: Berhenti di frame ke berapa.\n",
    "- class: Apa nama aksi untuk segmen frame tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "((lihat output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:06:24.482751Z",
     "iopub.status.busy": "2025-06-30T14:06:24.482200Z",
     "iopub.status.idle": "2025-06-30T14:06:25.044479Z",
     "shell.execute_reply": "2025-06-30T14:06:25.043865Z",
     "shell.execute_reply.started": "2025-06-30T14:06:24.482727Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating master DataFrame from labels...\n",
      "DataFrame created with 5648 clips.\n",
      "\n",
      "Class Distribution:\n",
      "class\n",
      "0     460\n",
      "1    1669\n",
      "2    1559\n",
      "3     506\n",
      "4     655\n",
      "5     799\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_1</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_1</td>\n",
       "      <td>177</td>\n",
       "      <td>229</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_1</td>\n",
       "      <td>235</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_1</td>\n",
       "      <td>256</td>\n",
       "      <td>290</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_1</td>\n",
       "      <td>299</td>\n",
       "      <td>525</td>\n",
       "      <td>4</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id  start_frame  end_frame  class  duration\n",
       "0     10_1            0        176      0       176\n",
       "1     10_1          177        229      5        52\n",
       "2     10_1          235        256      1        21\n",
       "3     10_1          256        290      2        34\n",
       "4     10_1          299        525      4       226"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from scipy.io import loadmat # fungsi khusus dari matlab untuk membaca format mat\n",
    "import numpy as np\n",
    "\n",
    "# Fungsi untuk load label .mat\n",
    "def load_mat_labels(label_path):\n",
    "    try:\n",
    "        mat_data = loadmat(label_path) # mengubah ke dict\n",
    "        if 'tlabs' in mat_data: return mat_data['tlabs']\n",
    "        data_keys = [k for k in mat_data.keys() if not k.startswith('__')]\n",
    "        if data_keys: return mat_data[data_keys[0]]\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {label_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fungsi baru untuk membuat DataFrame berisi informasi klip\n",
    "def create_clips_dataframe(videos_dir, labels_dir):\n",
    "    all_clips_data = []\n",
    "    video_paths = sorted(glob.glob(os.path.join(videos_dir, \"*_crop.mp4\")))\n",
    "    \n",
    "    # Kita butuh FPS untuk konversi frame nanti. Asumsikan 30 FPS.\n",
    "    # Jika berbeda, decord akan membacanya nanti.\n",
    "    fps_skip = 2 # Dari 30fps di video asli ke 15fps target\n",
    "\n",
    "    for video_path in video_paths:\n",
    "        match = re.search(r'(\\d+)_(\\d+)_crop\\.mp4', os.path.basename(video_path))\n",
    "        if not match: continue\n",
    "        \n",
    "        base_id, sub_id = match.groups()\n",
    "        video_id_str = f\"{base_id}_{sub_id}\"\n",
    "        \n",
    "        label_path = os.path.join(labels_dir, f\"{video_id_str}_label.mat\")\n",
    "        if not os.path.exists(label_path): continue\n",
    "\n",
    "        labels_data = load_mat_labels(label_path)\n",
    "        if labels_data is None: continue\n",
    "\n",
    "        # membuat interval aksi dari .mat\n",
    "        action_intervals = []\n",
    "        for class_idx, class_actions in enumerate(labels_data):\n",
    "            if len(class_actions[0]) > 0:\n",
    "                for start_frame, end_frame in class_actions[0]:\n",
    "                    action_intervals.append({\n",
    "                        'start': int(start_frame) - 1, # 0-based\n",
    "                        'end': int(end_frame) - 1,   # 0-based\n",
    "                        'class': class_idx + 1  # 1-5\n",
    "                    })\n",
    "        action_intervals.sort(key=lambda x: x['start'])\n",
    "\n",
    "        # membuat klip, termasuk kelas BACKGROUND\n",
    "        current_frame = 0\n",
    "        # video_total_frames = 10000 # Placeholder, akan dibaca decord nanti\n",
    "        \n",
    "        for interval in action_intervals:\n",
    "            if current_frame < interval['start']: # jika ada jeda (tidak ada aksi)\n",
    "                all_clips_data.append({\n",
    "                    'video_id': video_id_str,\n",
    "                    'start_frame': current_frame,\n",
    "                    'end_frame': interval['start'] - 1,\n",
    "                    'class': 0 # Background\n",
    "                })\n",
    "            \n",
    "            all_clips_data.append({\n",
    "                'video_id': video_id_str,\n",
    "                'start_frame': interval['start'],\n",
    "                'end_frame': interval['end'],\n",
    "                'class': interval['class']\n",
    "            })\n",
    "            current_frame = interval['end'] + 1\n",
    "        \n",
    "        # Sisa klip background di akhir\n",
    "        # Kita tidak perlu ini sekarang, biarkan Dataset yang mengaturnya nanti\n",
    "    \n",
    "    return pd.DataFrame(all_clips_data)\n",
    "\n",
    "# Buat DataFrame utama\n",
    "print(\"Creating master DataFrame from labels...\")\n",
    "combined_df = create_clips_dataframe(VIDEOS_DIR, LABELS_DIR)\n",
    "\n",
    "# Hapus klip yang terlalu pendek\n",
    "min_clip_length = 16 # Minimal 16 frame @30fps, atau ~0.5 detik\n",
    "combined_df['duration'] = combined_df['end_frame'] - combined_df['start_frame']\n",
    "combined_df = combined_df[combined_df['duration'] >= min_clip_length].reset_index(drop=True)\n",
    "\n",
    "print(f\"DataFrame created with {len(combined_df)} clips.\")\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(combined_df['class'].value_counts().sort_index())\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:06:35.668191Z",
     "iopub.status.busy": "2025-06-30T14:06:35.667490Z",
     "iopub.status.idle": "2025-06-30T14:06:36.138998Z",
     "shell.execute_reply": "2025-06-30T14:06:36.138033Z",
     "shell.execute_reply.started": "2025-06-30T14:06:35.668166Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split successfully:\n",
      "  Training set:   3953 clips\n",
      "  Validation set: 847 clips\n",
      "  Test set:       848 clips\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data 70% train, 15% validation, 15% test\n",
    "train_df, temp_df = train_test_split(\n",
    "    combined_df,\n",
    "    test_size=0.3,\n",
    "    stratify=combined_df['class'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['class'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Data split successfully:\")\n",
    "print(f\"  Training set:   {len(train_df)} clips\")\n",
    "print(f\"  Validation set: {len(val_df)} clips\")\n",
    "print(f\"  Test set:       {len(test_df)} clips\")\n",
    "\n",
    "# train_df_subset = train_df.sample(frac=0.5, random_state=42)\n",
    "# val_df_subset = val_df.sample(frac=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Utilitas Pembacaan Segmen Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fungsi MerlVideoDataset() ini cukup penting, bisa dibilang dia yg \"memotong\", sebenrnya cuma membaca segmen video dengan decord (lebih fleksibel dan efisien).\n",
    "\n",
    "di kode cukup jelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:06:41.728648Z",
     "iopub.status.busy": "2025-06-30T14:06:41.728228Z",
     "iopub.status.idle": "2025-06-30T14:06:45.060070Z",
     "shell.execute_reply": "2025-06-30T14:06:45.059524Z",
     "shell.execute_reply.started": "2025-06-30T14:06:41.728625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from decord import VideoReader, cpu\n",
    "\n",
    "class MerlVideoDataset(Dataset):\n",
    "    def __init__(self, df, image_processor, videos_dir, num_frames=16):\n",
    "        self.df = df\n",
    "        self.image_processor = image_processor\n",
    "        self.videos_dir = videos_dir\n",
    "        self.num_frames = num_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        video_path = os.path.join(self.videos_dir, f\"{row['video_id']}_crop.mp4\")\n",
    "\n",
    "        # Baca video dengan decord\n",
    "        vr = VideoReader(video_path, ctx=cpu(0))\n",
    "        total_frames_in_video = len(vr)\n",
    "\n",
    "        # Ambil frame indices dari klip yang didefinisikan\n",
    "        start_frame = row['start_frame'] # <- Membaca instruksi frame awal\n",
    "        end_frame = row['end_frame'] # <- Membaca instruksi frame akhir\n",
    "        \n",
    "        # Buat sampel frame secara merata di dalam klip\n",
    "        indices = np.linspace(start_frame, end_frame, num=self.num_frames, dtype=int)\n",
    "        indices = np.clip(indices, 0, total_frames_in_video - 1)\n",
    "\n",
    "        # Ambil frame yang dibutuhkan secara efisien\n",
    "        frames = vr.get_batch(indices).asnumpy() # <- di sini frame dibaca\n",
    "\n",
    "        # Proses menggunakan processor dari Hugging Face (normalisasi, resize)\n",
    "        processed_frames = self.image_processor(list(frames), return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": processed_frames.pixel_values.squeeze(0), # Hapus dimensi batch\n",
    "            \"labels\": torch.tensor(row['class'], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter for TrainingArgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Menggunakan class weight untuk berusaha menyeimbangkan imbalanced data\n",
    "2. Mendefinisikan CustomTrainer yang inheritance dari Trainer, sedikit ditambahkan supaya loss function dari CrossEntropyLoss bisa menggunakan bobot dari weight yg sebelumnya dibahas.\n",
    "3. Mendefinisikan paramater untuk training\n",
    "4. Inisiasi trainer dengan Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:06:48.813056Z",
     "iopub.status.busy": "2025-06-30T14:06:48.812644Z",
     "iopub.status.idle": "2025-06-30T14:07:16.178747Z",
     "shell.execute_reply": "2025-06-30T14:07:16.177469Z",
     "shell.execute_reply.started": "2025-06-30T14:06:48.813033Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 14:06:54.785078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751292415.000882      92 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751292415.063865      92 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚖️ Menghitung bobot kelas untuk mengatasi data tidak seimbang...\n",
      "Bobot Kelas yang akan digunakan: [2.0463767  0.5640104  0.60380584 1.8603425  1.4371501  1.1781393 ]\n",
      "\n",
      "🔄 Memuat model TimeSformer dan image processor...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0127a4edd14ba5aa6bd56ce0b17744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/412 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d92959f88d141a99d5f92b0035ad2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4787f755d6584aa19431920e2e6289b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a546101392464c82868771ee4b8341f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimesformerForVideoClassification were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k400 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Membuat instance PyTorch Dataset...\n",
      "⚙️ Mengkonfigurasi argumen training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af667110ad43bd95f7d22c42b9296c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ Menginisialisasi CustomTrainer dengan class weights...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoImageProcessor, AutoModelForVideoClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Definisikan Bobot Kelas (Class Weights)\n",
    "print(\"Menghitung bobot kelas untuk mengatasi data tidak seimbang...\")\n",
    "class_counts = combined_df['class'].value_counts().sort_index().values\n",
    "total_samples = class_counts.sum()\n",
    "num_classes = len(class_counts)\n",
    "class_weights = total_samples / (num_classes * class_counts)\n",
    "# Ubah ke tensor PyTorch dan pindahkan ke GPU\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(\"cuda\")\n",
    "\n",
    "print(f\"Bobot Kelas yang akan digunakan: {class_weights_tensor.cpu().numpy()}\")\n",
    "\n",
    "\n",
    "# Buat Custom Trainer untuk Menggunakan Bobot \n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # Hitung loss dengan bobot yang sudah kita definisikan\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# Definisikan label dan checkpoint model\n",
    "class_names = [\"Background\", \"Reach To Shelf\", \"Retract From Shelf\", \"Hand In Shelf\", \"Inspect Product\", \"Inspect Shelf\"]\n",
    "label2id = {name: i for i, name in enumerate(class_names)}\n",
    "id2label = {i: name for i, name in enumerate(class_names)}\n",
    "model_ckpt = \"facebook/timesformer-base-finetuned-k400\"\n",
    "\n",
    "# Muat Image Processor dan Model\n",
    "print(\"\\n Memuat model TimeSformer dan image processor...\")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_ckpt)\n",
    "model = AutoModelForVideoClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    num_labels=len(class_names),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "# Buat instance Dataset (gunakan kode dari langkah 5 Anda)\n",
    "print(\" Membuat instance PyTorch Dataset...\")\n",
    "train_dataset = MerlVideoDataset(train_df, image_processor, VIDEOS_DIR)\n",
    "val_dataset = MerlVideoDataset(val_df, image_processor, VIDEOS_DIR)\n",
    "\n",
    "# pake subset 50 persen dulu\n",
    "# train_dataset = MerlVideoDataset(train_df_subset, image_processor, VIDEOS_DIR)\n",
    "# val_dataset = MerlVideoDataset(val_df_subset, image_processor, VIDEOS_DIR)\n",
    "\n",
    "# Definisikan Argumen Training\n",
    "print(\" Mengkonfigurasi argumen training...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(WORK_DIR, \"timesformer-merl-weighted-loss\"),\n",
    "    per_device_train_batch_size=2,  \n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5, \n",
    "    learning_rate=3e-5, # Sedikit turunkan learning rate, kadang lebih stabil\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.05,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Definisikan Fungsi Metrik\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "# Gunakan CustomTrainer, bukan Trainer biasa\n",
    "print(\"Menginisialisasi CustomTrainer dengan class weights...\")\n",
    "trainer = CustomTrainer( # <-- Gunakan CustomTrainer\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=image_processor,\n",
    ")\n",
    "\n",
    "# kenapa pake custom trainer? apakah karena karena ingi memanfaatkan classweight? YA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Sampel: 5648\n",
    "\n",
    "Jumlah Kelas: 6\n",
    "\n",
    "Bobot Kelas 0 = 5648 / (6 * 460) = 2.04\n",
    "\n",
    "Bobot Kelas 1 = 5648 / (6 * 1669) = 0.56\n",
    "\n",
    "Bobot Kelas 2 = 5648 / (6 * 1559) = 0.60\n",
    "\n",
    "Bobot Kelas 3 = 5648 / (6 * 506) = 1.86\n",
    "\n",
    "Bobot Kelas 4 = 5648 / (6 * 655) = 1.44\n",
    "\n",
    "Bobot Kelas 5 = 5648 / (6 * 799) = 1.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:07:22.292852Z",
     "iopub.status.busy": "2025-06-30T14:07:22.292197Z",
     "iopub.status.idle": "2025-06-30T20:01:48.624586Z",
     "shell.execute_reply": "2025-06-30T20:01:48.623943Z",
     "shell.execute_reply.started": "2025-06-30T14:07:22.292827Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 5:54:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.246800</td>\n",
       "      <td>0.986131</td>\n",
       "      <td>0.621015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.710100</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.671783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.435800</td>\n",
       "      <td>0.914014</td>\n",
       "      <td>0.646989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.887493</td>\n",
       "      <td>0.669421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>0.683589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training completed\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "print(\"training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "logs = trainer.state.log_history\n",
    "log_df = pd.DataFrame(logs)\n",
    "# %cd /kaggle/working\n",
    "# !mkdir /outputnya/\n",
    "output_dir = \"/kaggle/working/output\"\n",
    "log_df.to_csv(os.path.join(output_dir, \"training_logs.csv\"), index=False)\n",
    "print(\"Logs saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Inference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aku udah upload dataset ke huggingface, jadi tinggal panggil.\n",
    "2. Buat test_dataset\n",
    "3. Predict, lalu hitung performanya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model_trained_before = \"haipradana/test-m-e-r-l\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "test_image_processor = AutoImageProcessor.from_pretrained(model_trained_before)\n",
    "test_model = AutoModelForVideoClassification.from_pretrained(model_trained_before).to(device)\n",
    "\n",
    "test_dataset = MerlVideoDataset(\n",
    "    df=test_df,\n",
    "    image_processor=test_image_processor,\n",
    "    videos_dir=VIDEOS_DIR\n",
    ")\n",
    "\n",
    "test_args = TrainingArguments(\n",
    "    output_dir=\"./test_results\",\n",
    "    per_device_eval_batch_size=4, \n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "tester = Trainer(\n",
    "    model=test_model,\n",
    "    args=test_args,\n",
    ")\n",
    "\n",
    "print(\"\\nMenjalankan prediksi pada test set...\")\n",
    "predictions = tester.predict(test_dataset)\n",
    "print(\"Prediksi selesai\")\n",
    "\n",
    "# Ambil prediksi (logits) dan label sebenarnya\n",
    "predicted_logits = predictions.predictions\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Ubah logits menjadi ID kelas yang diprediksi\n",
    "predicted_labels = np.argmax(predicted_logits, axis=1)\n",
    "\n",
    "# Dapatkan nama kelas dari `id2label` yang sudah didefinisikan sebelumnya\n",
    "target_names = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "# Hitung dan cetak laporan klasifikasi (precision, recall, f1-score)\n",
    "print(\"\\n--- Laporan Klasifikasi ---\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=target_names))\n",
    "\n",
    "# Hitung dan cetak akurasi keseluruhan\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Akurasi Keseluruhan: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Laporan Klasifikasi TEST  ---\n",
    "#                    precision    recall  f1-score   support\n",
    "\n",
    "#        Background       0.54      0.68      0.60        69\n",
    "#    Reach To Shelf       0.52      0.54      0.53       251\n",
    "#Retract From Shelf       0.52      0.44      0.47       234\n",
    "#     Hand In Shelf       0.61      0.71      0.65        76\n",
    "#   Inspect Product       0.67      0.73      0.70        98\n",
    "#     Inspect Shelf       0.84      0.75      0.79       120\n",
    "\n",
    "#          accuracy                           0.59       848\n",
    "#         macro avg       0.62      0.64      0.63       848\n",
    "#      weighted avg       0.59      0.59      0.59       848\n",
    "\n",
    "#Akurasi Keseluruhan: 0.5908"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COnfusion matriks. model masih agak bingung dalam membedakan mana yang retract mana yang reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels, normalize='true')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix pada Test Set')\n",
    "plt.ylabel('Label Asli (True Label)')\n",
    "plt.xlabel('Label Prediksi (Predicted Label)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Confusion Matrix](confusion_matrix_merl.png)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
