{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b93852df",
      "metadata": {
        "id": "b93852df"
      },
      "outputs": [],
      "source": [
        "# CELL 1: Install dependencies\n",
        "!pip install ultralytics supervision transformers[torch] accelerate decord datasets evaluate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3562f310",
      "metadata": {
        "id": "3562f310"
      },
      "outputs": [],
      "source": [
        "# CELL 2: Import libraries\n",
        "import os, cv2, csv\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from datetime import timedelta\n",
        "from ultralytics import YOLO\n",
        "from transformers import AutoImageProcessor, AutoModelForVideoClassification\n",
        "from decord import VideoReader, cpu\n",
        "import supervision as sv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UrqFhuP5FAgZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "a12444c2db8f4bfda8539c03e55ef7c0",
            "6d74e8bc758b402e8fd5b4bd0ccc9fe3",
            "265200bb80584a3fabdebaba826dcd58",
            "dee7f0649e434726ac7224b8a8c23ce5",
            "526e58ddee8648989b2f87165888d60d",
            "8d18b0f62678450f8d0daf0f14bf7e03",
            "a97e70b58a6f4ac5b16c8e0ddcaf1688",
            "94b792a1951d49eba249df749e6fa1f6",
            "a78e982ac2244782a1c82e23fc72f31b",
            "b51cff4709da4d97b0cb091e9109e7f5",
            "79397584d37e41ba9e0cb663c0c81054"
          ]
        },
        "id": "UrqFhuP5FAgZ",
        "outputId": "f59df726-8709-49a5-c4f8-a972be12708c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a12444c2db8f4bfda8539c03e55ef7c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/shelf_model'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(repo_id=\"cheesecz/shelf-segmentation\", local_dir=\"shelf_model\", local_dir_use_symlinks=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "maJ6MVSYUq9P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maJ6MVSYUq9P",
        "outputId": "7586ebca-a03a-4eac-9709-17b39f24a0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'Shelf'}\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"shelf_model/best.pt\")\n",
        "print(model.names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c19ee6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0c19ee6",
        "outputId": "00444694-e943-4e84-a3fe-f1cb45ff2e21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        }
      ],
      "source": [
        "# CELL 3: Load models\n",
        "person_model = YOLO('yolo11s.pt')\n",
        "shelf_model = YOLO(\"shelf_model/best.pt\")\n",
        "action_model = AutoModelForVideoClassification.from_pretrained('haipradana/s-h-o-p-domain-adaptation')\n",
        "image_processor = AutoImageProcessor.from_pretrained('haipradana/s-h-o-p-domain-adaptation')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "action_model.to(device).eval()\n",
        "id2label = action_model.config.id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf89d5cf",
      "metadata": {
        "id": "bf89d5cf"
      },
      "outputs": [],
      "source": [
        "# CELL 4: Merge consecutive predictions\n",
        "def merge_consecutive_predictions(preds, min_duration_frames=0):\n",
        "    if not preds: return []\n",
        "    merged = []\n",
        "    current = preds[0].copy()\n",
        "    for nxt in preds[1:]:\n",
        "        if nxt['pred'] == current['pred']:\n",
        "            current['end'] = nxt['end']\n",
        "        else:\n",
        "            merged.append(current)\n",
        "            current = nxt.copy()\n",
        "    merged.append(current)\n",
        "    return [e for e in merged if (e['end'] - e['start']) >= min_duration_frames]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffe84336",
      "metadata": {
        "id": "ffe84336"
      },
      "outputs": [],
      "source": [
        "# CELL 5: Segment shelf from a static image\n",
        "def infer_shelf_segmentation(image_path):\n",
        "    result = shelf_model(image_path)\n",
        "    result[0].save(filename=f'result_shelf_{os.path.basename(image_path)}')\n",
        "    return f'result_shelf_{os.path.basename(image_path)}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g2mU1s76eUHc",
      "metadata": {
        "id": "g2mU1s76eUHc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def generate_rak_timeline(interaction_csv_path, tracks, shelf_boxes_per_frame, fps, output_path='timeline_rak.png'):\n",
        "    \"\"\"\n",
        "    Membuat timeline visual interaksi orang terhadap rak.\n",
        "    Menyimpan hasil ke file PNG.\n",
        "\n",
        "    Params:\n",
        "        interaction_csv_path (str): path ke rak_interaksi.csv\n",
        "        tracks (dict): hasil tracking orang (per ID)\n",
        "        shelf_boxes_per_frame (dict): koordinat rak per frame\n",
        "        fps (float): frame rate video\n",
        "        output_path (str): path file PNG hasil\n",
        "    \"\"\"\n",
        "\n",
        "    # Ambil daftar rak valid (sudah difilter)\n",
        "    rak_df = pd.read_csv(interaction_csv_path)\n",
        "    valid_raks = set(rak_df['rak_id'].tolist())\n",
        "\n",
        "    # Bangun timeline per rak\n",
        "    rak_timeline = defaultdict(list)\n",
        "    for pid, dets in tracks.items():\n",
        "        for d in dets:\n",
        "            f = d['frame']\n",
        "            x1, y1, x2, y2 = d['bbox']\n",
        "            px, py = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "            for sb in shelf_boxes_per_frame.get(f, []):\n",
        "                sx1, sy1, sx2, sy2 = sb\n",
        "                rak_id = f\"rak_{int(sx1)}_{int(sy1)}\"\n",
        "                if rak_id not in valid_raks:\n",
        "                    continue\n",
        "                if sx1 <= px <= sx2 and sy1 <= py <= sy2:\n",
        "                    rak_timeline[rak_id].append(f)\n",
        "\n",
        "    # Buat visualisasi\n",
        "    plt.figure(figsize=(12, max(4, len(rak_timeline) * 0.4)))\n",
        "    for i, (rak_id, frames) in enumerate(sorted(rak_timeline.items())):\n",
        "        if not frames:\n",
        "            continue\n",
        "        frames = sorted(frames)\n",
        "        start = frames[0]\n",
        "        for j in range(1, len(frames)):\n",
        "            if frames[j] != frames[j-1] + 1:\n",
        "                plt.plot([start / fps, frames[j-1] / fps], [i, i], linewidth=6)\n",
        "                start = frames[j]\n",
        "        plt.plot([start / fps, frames[-1] / fps], [i, i], linewidth=6)\n",
        "        plt.text(-1, i, rak_id, verticalalignment='center', fontsize=8)\n",
        "\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.title('Timeline Interaksi per Rak')\n",
        "    plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path)\n",
        "    plt.close()\n",
        "\n",
        "    return output_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96e1e1e0",
      "metadata": {
        "id": "96e1e1e0"
      },
      "outputs": [],
      "source": [
        "# # CELL 6: Main video processing with all features + rak filter + display ID\n",
        "# def full_video_analysis(video_path, output_dir):\n",
        "#     vr = VideoReader(video_path, ctx=cpu(0))\n",
        "#     fps = vr.get_avg_fps()\n",
        "#     H, W, _ = vr[0].shape\n",
        "#     out_path = os.path.join(output_dir, 'video_output.mp4')\n",
        "#     vw = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (W, H))\n",
        "#     tracker = person_model.track(source=video_path, persist=True, tracker='bytetrack.yaml', classes=[0], stream=True)\n",
        "\n",
        "#     tracks, raw_actions, heatmap_grid = defaultdict(list), defaultdict(list), np.zeros((20, 20))\n",
        "#     shelf_boxes_per_frame = {}\n",
        "\n",
        "#     for idx, result in enumerate(tracker):\n",
        "#         frame = vr[idx].asnumpy()\n",
        "#         frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "#         res_shelf = shelf_model(frame)\n",
        "#         shelf_boxes = [b.xyxy[0].cpu().numpy() for b in res_shelf[0].boxes] if res_shelf[0].boxes else []\n",
        "#         shelf_boxes_per_frame[idx] = shelf_boxes\n",
        "\n",
        "#         if result.boxes.id is not None:\n",
        "#             boxes = result.boxes.xyxy.cpu().numpy()\n",
        "#             ids = result.boxes.id.int().cpu().tolist()\n",
        "#             for box, pid in zip(boxes, ids):\n",
        "#                 tracks[pid].append({'frame': idx, 'bbox': box})\n",
        "#                 x, y = (box[0] + box[2])/2, (box[1] + box[3])/2\n",
        "#                 gx, gy = min(int(x / W * 20), 19), min(int(y / H * 20), 19)\n",
        "#                 heatmap_grid[gy, gx] += 1\n",
        "\n",
        "#     # === FILTER RAK: hanya simpan rak yang muncul di minimal N frame\n",
        "#     MIN_FRAME_RAK = 0\n",
        "#     rak_counter = defaultdict(int)\n",
        "#     for f, shelf_boxes in shelf_boxes_per_frame.items():\n",
        "#         for sb in shelf_boxes:\n",
        "#             sx1, sy1, sx2, sy2 = map(int, sb)\n",
        "#             rak_id = f\"rak_{int(sx1)}_{int(sy1)}\"\n",
        "#             rak_counter[rak_id] += 1\n",
        "#     valid_rak_ids = {rak_id for rak_id, count in rak_counter.items() if count >= MIN_FRAME_RAK}\n",
        "\n",
        "#     # === Action recognition\n",
        "#     for pid, dets in tracks.items():\n",
        "#         if len(dets) < 16: continue\n",
        "#         for i in range(0, len(dets)-16+1, 8):\n",
        "#             frames = vr.get_batch([d['frame'] for d in dets[i:i+16]]).asnumpy()\n",
        "#             crops = [f[int(d['bbox'][1]):int(d['bbox'][3]), int(d['bbox'][0]):int(d['bbox'][2])] for f, d in zip(frames, dets[i:i+16])]\n",
        "#             if not crops: continue\n",
        "#             inputs = image_processor(crops, return_tensors='pt').to(device)\n",
        "#             with torch.no_grad():\n",
        "#                 out = action_model(**inputs)\n",
        "#             pred = out.logits.argmax(-1).item()\n",
        "#             raw_actions[pid].append({'start': dets[i]['frame'], 'end': dets[i+15]['frame'], 'pred': pred})\n",
        "\n",
        "#     action_preds = {pid: merge_consecutive_predictions(plist, int(fps*0.4)) for pid, plist in raw_actions.items()}\n",
        "\n",
        "#     # === Hitung interaksi ke rak\n",
        "#     rak_interaksi = defaultdict(int)\n",
        "#     for pid, dets in tracks.items():\n",
        "#         for d in dets:\n",
        "#             f = d['frame']\n",
        "#             x1, y1, x2, y2 = d['bbox']\n",
        "#             px, py = (x1+x2)/2, (y1+y2)/2\n",
        "#             for sb in shelf_boxes_per_frame.get(f, []):\n",
        "#                 sx1, sy1, sx2, sy2 = sb\n",
        "#                 rak_id = f\"rak_{int(sx1)}_{int(sy1)}\"\n",
        "#                 if rak_id not in valid_rak_ids:\n",
        "#                     continue\n",
        "#                 if sx1 <= px <= sx2 and sy1 <= py <= sy2:\n",
        "#                     rak_interaksi[rak_id] += 1\n",
        "\n",
        "#     # === Simpan rekap interaksi rak\n",
        "#     pd.DataFrame(list(rak_interaksi.items()), columns=['rak_id', 'interaksi']).to_csv(\n",
        "#         os.path.join(output_dir, 'rak_interaksi.csv'), index=False)\n",
        "#     pd.DataFrame(sorted(rak_interaksi.items(), key=lambda x: -x[1]), columns=['rak_id', 'interaksi']).to_csv(\n",
        "#         os.path.join(output_dir, 'rekomendasi_layout.csv'), index=False)\n",
        "\n",
        "#     # === Save heatmap\n",
        "#     plt.imshow(heatmap_grid, cmap='hot', interpolation='nearest')\n",
        "#     plt.title('Heatmap of Visitor Presence')\n",
        "#     plt.colorbar()\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(os.path.join(output_dir, 'heatmap.png'))\n",
        "#     plt.close()\n",
        "\n",
        "#     # === Simpan log aksi\n",
        "#     all_actions = []\n",
        "#     for pid, acts in action_preds.items():\n",
        "#         for a in acts:\n",
        "#             all_actions.append([pid, a['start'], a['end'], id2label[a['pred']]])\n",
        "#     pd.DataFrame(all_actions, columns=['id', 'start', 'end', 'action']).to_csv(\n",
        "#         os.path.join(output_dir, 'action_log.csv'), index=False)\n",
        "#     pd.DataFrame(pd.Series([x[3] for x in all_actions]).value_counts()).to_csv(\n",
        "#         os.path.join(output_dir, 'action_summary.csv'))\n",
        "\n",
        "#     # === Render video dengan rak & heatmap overlay\n",
        "#     heatmap_annotator = sv.HeatMapAnnotator(position=sv.Position.BOTTOM_CENTER, opacity=0.3, radius=20, kernel_size=25)\n",
        "\n",
        "#     for idx in range(len(vr)):\n",
        "#         frame = vr[idx].asnumpy()\n",
        "#         frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "#         shelf_result = shelf_model(frame_bgr)\n",
        "#         if hasattr(shelf_result[0], \"masks\") and shelf_result[0].masks is not None:\n",
        "#             mask_img = shelf_result[0].masks.data.cpu().numpy().sum(axis=0)\n",
        "#             mask_img = (mask_img > 0).astype(np.uint8) * 100\n",
        "#             mask_img = cv2.resize(mask_img, (frame_bgr.shape[1], frame_bgr.shape[0]))  # resize to match frame\n",
        "#             mask_img = cv2.applyColorMap(mask_img, cv2.COLORMAP_JET)\n",
        "#             mask_img = cv2.cvtColor(mask_img, cv2.COLOR_BGR2RGB)  # pastikan sama format warna\n",
        "#             frame_bgr = cv2.addWeighted(frame_bgr, 1.0, mask_img, 0.4, 0)\n",
        "\n",
        "\n",
        "#         # Rak overlay (filtered + labeled)\n",
        "#         for sb in shelf_boxes_per_frame.get(idx, []):\n",
        "#             x1, y1, x2, y2 = map(int, sb)\n",
        "#             rak_id = f\"rak_{x1}_{y1}\"\n",
        "#             if rak_id not in valid_rak_ids:\n",
        "#                 continue\n",
        "#             cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "#             cv2.putText(frame_bgr, rak_id, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "#         # Tracking & action label\n",
        "#         current_tracks = [t for pid, dets in tracks.items() for t in dets if t['frame'] == idx]\n",
        "#         for t in current_tracks:\n",
        "#             x1, y1, x2, y2 = map(int, t['bbox'])\n",
        "#             t_frame, t_bbox = t['frame'], t['bbox']\n",
        "#             pid = next(\n",
        "#                 (pid for pid, dets in tracks.items()\n",
        "#                  if any(d['frame'] == t_frame and np.allclose(d['bbox'], t_bbox) for d in dets)),\n",
        "#                 None\n",
        "#             )\n",
        "#             label = f\"ID {pid}\"\n",
        "#             for a in action_preds.get(pid, []):\n",
        "#                 if a['start'] <= idx <= a['end']:\n",
        "#                     label += f\" | {id2label[a['pred']]}\"\n",
        "#                     break\n",
        "#             cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "#             cv2.putText(frame_bgr, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "#         # Overlay heatmap\n",
        "#         detections = sv.Detections(\n",
        "#             xyxy=np.array([t['bbox'] for t in current_tracks]),\n",
        "#             confidence=np.ones(len(current_tracks)),\n",
        "#             class_id=np.zeros(len(current_tracks))\n",
        "#         )\n",
        "#         frame_bgr = heatmap_annotator.annotate(scene=frame_bgr.copy(), detections=detections)\n",
        "\n",
        "#         vw.write(frame_bgr)\n",
        "\n",
        "#     vw.release()\n",
        "\n",
        "#         # === Generate timeline visual interaksi per rak\n",
        "#     generate_rak_timeline(\n",
        "#         interaction_csv_path=os.path.join(output_dir, 'rak_interaksi.csv'),\n",
        "#         tracks=tracks,\n",
        "#         shelf_boxes_per_frame=shelf_boxes_per_frame,\n",
        "#         fps=fps,\n",
        "#         output_path=os.path.join(output_dir, 'timeline_rak.png')\n",
        "#     )\n",
        "\n",
        "#     return out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G7zEscHpGTiW",
      "metadata": {
        "id": "G7zEscHpGTiW"
      },
      "outputs": [],
      "source": [
        "# CELL 6 : Main video processing -- with stable shelf_id + display\n",
        "from shapely.geometry import box as shp_box   # ← untuk IoU cepat\n",
        "\n",
        "def iou_xyxy(a, b):\n",
        "    \"\"\"a,b : (x1,y1,x2,y2) -> IoU 0-1\"\"\"\n",
        "    inter = shp_box(*a).intersection(shp_box(*b)).area\n",
        "    union = shp_box(*a).union(shp_box(*b)).area\n",
        "    return inter / union if union else 0\n",
        "\n",
        "def full_video_analysis(video_path, output_dir):\n",
        "    vr  = VideoReader(video_path, ctx=cpu(0))\n",
        "    fps = vr.get_avg_fps()\n",
        "    print(f\"FPS video = {fps:.2f}\")\n",
        "    H,W,_ = vr[0].shape\n",
        "    out_path = os.path.join(output_dir,'video_output.mp4')\n",
        "    vw  = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps,(W,H))\n",
        "\n",
        "    tracker   = person_model.track(source=video_path, persist=True,\n",
        "                                   tracker='bytetrack.yaml', classes=[0], stream=True)\n",
        "\n",
        "    tracks, raw_actions = defaultdict(list), defaultdict(list)\n",
        "    heatmap_grid        = np.zeros((20,20))\n",
        "\n",
        "    shelf_boxes_per_frame = {}                # idx -> [(shelf_id, xyxy)]\n",
        "    shelf_last_box        = {}                # shelf_id -> last xyxy\n",
        "    next_shelf_idx        = 1\n",
        "    IOU_TH = 0.5                               # threshold “geser dikit” dianggap sama rak\n",
        "\n",
        "    # ---------- PASS 1 : deteksi + tracking ----------\n",
        "    for f_idx, result in enumerate(tracker):\n",
        "        frame = vr[f_idx].asnumpy()\n",
        "        res_shelf = shelf_model(frame)\n",
        "\n",
        "        assigned = []\n",
        "        raw_boxes = [b.xyxy[0].cpu().numpy() for b in res_shelf[0].boxes] if res_shelf[0].boxes else []\n",
        "\n",
        "        for box in raw_boxes:\n",
        "            cur = tuple(map(int, box))\n",
        "            best_iou,best_id = 0,None\n",
        "            for sid, prev in shelf_last_box.items():\n",
        "                val = iou_xyxy(cur, prev)\n",
        "                if val>best_iou:\n",
        "                    best_iou,best_id = val, sid\n",
        "            if best_iou>=IOU_TH:\n",
        "                shelf_last_box[best_id] = cur\n",
        "                assigned.append((best_id,cur))\n",
        "            else:\n",
        "                sid = f\"shelf_{next_shelf_idx}\"\n",
        "                next_shelf_idx += 1\n",
        "                shelf_last_box[sid] = cur\n",
        "                assigned.append((sid,cur))\n",
        "\n",
        "        shelf_boxes_per_frame[f_idx] = assigned\n",
        "\n",
        "        # people tracks\n",
        "        if result.boxes.id is not None:\n",
        "            boxes = result.boxes.xyxy.cpu().numpy()\n",
        "            ids   = result.boxes.id.int().cpu().tolist()\n",
        "            for box,pid in zip(boxes,ids):\n",
        "                tracks[pid].append({'frame': f_idx, 'bbox': box, 'pid': pid})\n",
        "                cx,cy = (box[0]+box[2])/2,(box[1]+box[3])/2\n",
        "                gx,gy = min(int(cx/W*20),19), min(int(cy/H*20),19)\n",
        "                heatmap_grid[gy, gx] += 1\n",
        "\n",
        "    # ---------- Action recognition ----------\n",
        "    for pid,dets in tracks.items():\n",
        "        if len(dets)<16: continue\n",
        "        for i in range(0,len(dets)-15,8):\n",
        "            clip_frames = [d['frame'] for d in dets[i:i+16]]\n",
        "            imgs = vr.get_batch(clip_frames).asnumpy()\n",
        "            crops = [img[int(d['bbox'][1]):int(d['bbox'][3]),\n",
        "                         int(d['bbox'][0]):int(d['bbox'][2])] for img,d in zip(imgs,dets[i:i+16])]\n",
        "            if not crops: continue\n",
        "            inp = image_processor(crops, return_tensors='pt').to(device)\n",
        "            pred = action_model(**inp).logits.argmax(-1).item()\n",
        "            raw_actions[pid].append({'start':dets[i]['frame'],'end':dets[i+15]['frame'],'pred':pred})\n",
        "\n",
        "    action_preds = {pid:merge_consecutive_predictions(v,int(fps*0.4))\n",
        "                    for pid,v in raw_actions.items()}\n",
        "\n",
        "    # ---------- Hitung interaksi ke rak ----------\n",
        "    shelf_interaksi = defaultdict(int)\n",
        "    for pid,dets in tracks.items():\n",
        "        for d in dets:\n",
        "            f = d['frame']; x1,y1,x2,y2 = d['bbox']\n",
        "            cx,cy = (x1+x2)/2,(y1+y2)/2\n",
        "            for sid,(sx1,sy1,sx2,sy2) in shelf_boxes_per_frame.get(f,[]):\n",
        "                if sx1<=cx<=sx2 and sy1<=cy<=sy2:\n",
        "                    shelf_interaksi[sid]+=1\n",
        "\n",
        "    pd.DataFrame(list(shelf_interaksi.items()),\n",
        "                 columns=['shelf_id','interaksi']).to_csv(\n",
        "                 os.path.join(output_dir,'rak_interaksi.csv'), index=False)\n",
        "\n",
        "    # ---------- Heatmap gambar ----------\n",
        "    plt.imshow(heatmap_grid,cmap='hot',interpolation='nearest')\n",
        "    plt.title('Heatmap of Visitor Presence'); plt.colorbar(); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir,'heatmap.png')); plt.close()\n",
        "\n",
        "\n",
        "    # ---------- Rekap aksi (log + summary) ----------\n",
        "    all_actions = []\n",
        "    for pid, acts in action_preds.items():\n",
        "        for a in acts:\n",
        "            all_actions.append([pid, a['start'], a['end'], id2label[a['pred']]])\n",
        "\n",
        "    pd.DataFrame(all_actions,\n",
        "                 columns=['id', 'start', 'end', 'action']).to_csv(\n",
        "                 os.path.join(output_dir, 'action_log.csv'), index=False)\n",
        "\n",
        "    pd.DataFrame(pd.Series([row[3] for row in all_actions])\n",
        "                 .value_counts()).to_csv(\n",
        "                 os.path.join(output_dir, 'action_summary.csv'))\n",
        "\n",
        "    # ---------- Action ↔ Shelf mapping ----------\n",
        "    action_shelf = []          # baris detail\n",
        "    shelf_action_counter = defaultdict(int)\n",
        "\n",
        "    for pid, acts in action_preds.items():\n",
        "        for seg in acts:\n",
        "            s, e, act_id = seg['start'], seg['end'], seg['pred']\n",
        "            act_label     = id2label[act_id]\n",
        "\n",
        "            # frame-frame di rentang aksi\n",
        "            for f in range(s, e+1):\n",
        "                # pusat bbox orang frame-f\n",
        "                det = next((d for d in tracks[pid] if d['frame']==f), None)\n",
        "                if det is None: continue\n",
        "                x1,y1,x2,y2 = det['bbox']; cx,cy = (x1+x2)/2,(y1+y2)/2\n",
        "\n",
        "                for sid,(sx1,sy1,sx2,sy2) in shelf_boxes_per_frame.get(f, []):\n",
        "                    if sx1<=cx<=sx2 and sy1<=cy<=sy2:\n",
        "                        action_shelf.append([pid, f, sid, act_label])\n",
        "                        shelf_action_counter[(sid, act_label)] += 1\n",
        "                        break   # satu rak saja cukup\n",
        "\n",
        "    # simpan detail\n",
        "    pd.DataFrame(action_shelf,\n",
        "                 columns=['pid', 'frame', 'shelf_id', 'action']).to_csv(\n",
        "                 os.path.join(output_dir, 'action_shelf_log.csv'), index=False)\n",
        "\n",
        "    # simpan ringkasan jumlah\n",
        "    pd.DataFrame(\n",
        "        [{'shelf_id':k[0], 'action':k[1], 'count':v}\n",
        "         for k,v in shelf_action_counter.items()]\n",
        "    ).to_csv(os.path.join(output_dir,'action_shelf_summary.csv'), index=False)\n",
        "\n",
        "\n",
        "    # ---------- Rekomendasi layout (rak tersibuk → tersunyi) ----------\n",
        "    pd.DataFrame(sorted(shelf_interaksi.items(),\n",
        "                        key=lambda x: -x[1]),\n",
        "                 columns=['shelf_id', 'interaksi']).to_csv(\n",
        "                 os.path.join(output_dir, 'rekomendasi_layout.csv'), index=False)\n",
        "\n",
        "\n",
        "    # ---------- Film dengan overlay ----------\n",
        "    heatmap_ann = sv.HeatMapAnnotator(position=sv.Position.BOTTOM_CENTER,\n",
        "                                      opacity=0.3,radius=20,kernel_size=25)\n",
        "\n",
        "    for f_idx in range(len(vr)):\n",
        "        frame = vr[f_idx].asnumpy()\n",
        "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # draw shelves\n",
        "        for sid,(x1,y1,x2,y2) in shelf_boxes_per_frame.get(f_idx,[]):\n",
        "            cv2.rectangle(frame_bgr,(x1,y1),(x2,y2),(255,0,0),2)\n",
        "            cv2.putText(frame_bgr,sid,(x1,y1-5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,0,0),2)\n",
        "\n",
        "        # draw persons\n",
        "        cur_tracks=[t for pid,v in tracks.items() for t in v if t['frame']==f_idx]\n",
        "        for t in cur_tracks:\n",
        "            x1,y1,x2,y2 = map(int,t['bbox'])\n",
        "            pid = t['pid']\n",
        "            label=f\"ID {pid}\"\n",
        "            for a in action_preds.get(pid,[]):\n",
        "                if a['start']<=f_idx<=a['end']:\n",
        "                    label+=f\" | {id2label[a['pred']]}\"\n",
        "                    break\n",
        "            cv2.rectangle(frame_bgr,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "            cv2.putText(frame_bgr,label,(x1,y1-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
        "\n",
        "        dets=sv.Detections(xyxy=np.array([t['bbox'] for t in cur_tracks]),\n",
        "                           confidence=np.ones(len(cur_tracks)),\n",
        "                           class_id=np.zeros(len(cur_tracks)))\n",
        "        frame_bgr = heatmap_ann.annotate(scene=frame_bgr.copy(), detections=dets)\n",
        "        vw.write(frame_bgr)\n",
        "\n",
        "    vw.release()\n",
        "    return out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_mXbdJhBD6M9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mXbdJhBD6M9",
        "outputId": "f40fbe70-5e60-4c5a-da7c-ccb5d550dd1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff45f1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6ff45f1c",
        "outputId": "2cfb2b8b-3a16-4b78-ba78-699bd7f12a80"
      },
      "outputs": [],
      "source": [
        "video_path = \"/content/drive/MyDrive/datathon_2025/videos/multiperson.mp4\"\n",
        "output_dir = \"/content/output\"\n",
        "\n",
        "# Jalankan analisis lengkap\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "video_result = full_video_analysis(video_path, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fz8NcfMkf7xc",
      "metadata": {
        "id": "Fz8NcfMkf7xc"
      },
      "outputs": [],
      "source": [
        "# df_log = pd.read_csv(os.path.join(output_dir, \"action_shelf_log.csv\"))\n",
        "\n",
        "# dwell_rows = []\n",
        "# for (pid, shelf), grp in df_log.groupby(['pid', 'shelf_id']):\n",
        "#     frames = sorted(grp['frame'].tolist())\n",
        "#     start = frames[0]\n",
        "#     prev  = frames[0]\n",
        "#     for fr in frames[1:]:\n",
        "#         if fr != prev + 1:          # terputus → segmen selesai\n",
        "#             dwell_rows.append([pid, shelf, start, prev,\n",
        "#                                prev - start + 1, (prev - start + 1)/fps])\n",
        "#             start = fr\n",
        "#         prev = fr\n",
        "#     # segmen terakhir\n",
        "#     dwell_rows.append([pid, shelf, start, prev,\n",
        "#                        prev - start + 1, (prev - start + 1)/fps])\n",
        "\n",
        "# pd.DataFrame(dwell_rows,\n",
        "#              columns=['pid','shelf_id','start_frame','end_frame',\n",
        "#                       'frames','seconds']).to_csv(\n",
        "#              os.path.join(output_dir, 'dwell_time.csv'), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1vsGmV9iO5em",
      "metadata": {
        "id": "1vsGmV9iO5em"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# from PIL import Image\n",
        "\n",
        "# # Upload file gambar dari lokal\n",
        "# uploaded = files.upload()  # kamu bisa pilih file dari komputer\n",
        "\n",
        "# # Ambil nama file pertama yang di-upload\n",
        "# image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# # Jalankan fungsi segmentasi\n",
        "# hasil_path = infer_shelf_segmentation(image_path)\n",
        "\n",
        "# # Tampilkan hasilnya\n",
        "# Image.open(hasil_path).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gllq0vY4dKdH",
      "metadata": {
        "id": "Gllq0vY4dKdH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "265200bb80584a3fabdebaba826dcd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b792a1951d49eba249df749e6fa1f6",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a78e982ac2244782a1c82e23fc72f31b",
            "value": 3
          }
        },
        "526e58ddee8648989b2f87165888d60d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d74e8bc758b402e8fd5b4bd0ccc9fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d18b0f62678450f8d0daf0f14bf7e03",
            "placeholder": "​",
            "style": "IPY_MODEL_a97e70b58a6f4ac5b16c8e0ddcaf1688",
            "value": "Fetching 3 files: 100%"
          }
        },
        "79397584d37e41ba9e0cb663c0c81054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d18b0f62678450f8d0daf0f14bf7e03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b792a1951d49eba249df749e6fa1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12444c2db8f4bfda8539c03e55ef7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d74e8bc758b402e8fd5b4bd0ccc9fe3",
              "IPY_MODEL_265200bb80584a3fabdebaba826dcd58",
              "IPY_MODEL_dee7f0649e434726ac7224b8a8c23ce5"
            ],
            "layout": "IPY_MODEL_526e58ddee8648989b2f87165888d60d"
          }
        },
        "a78e982ac2244782a1c82e23fc72f31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a97e70b58a6f4ac5b16c8e0ddcaf1688": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b51cff4709da4d97b0cb091e9109e7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee7f0649e434726ac7224b8a8c23ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51cff4709da4d97b0cb091e9109e7f5",
            "placeholder": "​",
            "style": "IPY_MODEL_79397584d37e41ba9e0cb663c0c81054",
            "value": " 3/3 [00:00&lt;00:00, 95.11it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
